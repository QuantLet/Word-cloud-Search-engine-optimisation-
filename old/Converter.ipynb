{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the PDF. \n",
    "Important to set the initial addresses of the import and export file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the PDF-text file\n",
    "assigning file adress for import and file location, file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: incorrect startxref pointer(0) [_reader.py:938]\n"
     ]
    }
   ],
   "source": [
    "file_address = \"/Users/ivankotik/Library/Mobile Documents/com~apple~CloudDocs/Humboldt University/Search engine/Word-cloud-Search-engine-optimisation-/testpdf3.pdf\"\n",
    "file_location = \"/Users/ivankotik/Library/Mobile Documents/com~apple~CloudDocs/Humboldt University/Search engine/Word-cloud-Search-engine-optimisation-/\"\n",
    "file_name = \"testjson4.json\"\n",
    "file_export = file_location + file_name\n",
    "imported_pdf = open(file_address, 'rb')\n",
    "transformed_pdf = PyPDF2.PdfFileReader(imported_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertation of the PDF to a string\n",
    "Transforming the PDF to string by page and combining it into one string file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the initial PDF page into a string\n",
    "pageObjc_zero = transformed_pdf.getPage(1)\n",
    "combined_pages = pageObjc_zero.extractText()\n",
    "\n",
    "# initiating cycle to add the other pages\n",
    "for i in range(2, transformed_pdf.numPages):\n",
    "    pageObjc_placeholder = transformed_pdf.getPage(i)\n",
    "    combined_pages = combined_pages + pageObjc_placeholder.extractText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGEX-pattern cleaning\n",
    "Data must be cleaned of empty spaces, web links and other junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting spaces\n",
    "combined_pages_w = combined_pages.strip()\n",
    "\n",
    "# lowercase\n",
    "combined_pages_w = combined_pages_w.lower()\n",
    "\n",
    "# deleting the newline command\n",
    "combined_pages_w = re.sub(pattern = \"\\n\", repl = \" \", string = combined_pages_w)\n",
    "\n",
    "# deleting the weblinks\n",
    "combined_pages_w = re.sub(pattern = \"http[^ ]*\", repl = \" \", string = combined_pages_w)\n",
    "\n",
    "# deleting numbers and brackets etc.\n",
    "combined_pages_w = re.sub(pattern = \"\\d\", repl = \"\", string = combined_pages_w)\n",
    "combined_pages_w = re.sub(pattern = \"(\\)|\\(|,|\\.|!|=|:|\\[|\\]|\\{|\\}|\\'|\\\"|#|<|>|\\%|\\&|\\?|\\*|\\/|-|\\$|\\+)\", repl = \"\", string = combined_pages_w)\n",
    "\n",
    "# deleting extra spaces\n",
    "combined_pages_w = re.sub(pattern = \"\\s{2,}\", repl = \" \", string = combined_pages_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stop words\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary creation\n",
    "Splitting the string into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dictionary\n",
    "dictionary = dict()\n",
    "\n",
    "# creating the word file\n",
    "words = combined_pages_w.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of swprds with len < 3\n",
    "words = [x for x in words if len(x) > 2]\n",
    "\n",
    "# filtering away stopword matches\n",
    "words = [x for x in words if x not in stopwords_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting all of the occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting word occurances\n",
    "for word in words:\n",
    "    if word in dictionary:\n",
    "        dictionary[word] = dictionary[word] + 1\n",
    "    else:\n",
    "        dictionary[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataframe to sort the words\n",
    "Also deleting \"-\"'s that are thought as of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dictionary\n",
    "dictionary_words = dictionary.items()\n",
    "\n",
    "# converting to the list\n",
    "dictionary_list = list(dictionary_words)\n",
    "\n",
    "# converting to a dataframe\n",
    "df_dictionary = pd.DataFrame(dictionary_list)\n",
    "\n",
    "# rename columns\n",
    "df_dictionary = df_dictionary.rename(columns={0:\"word\", 1:\"occurance\"})\n",
    "\n",
    "# sort values\n",
    "df_dictionary = df_dictionary.sort_values(\"occurance\", ascending=False)\n",
    "\n",
    "# re-indexing\n",
    "df_dictionary['index'] = range(len(df_dictionary))\n",
    "df_dictionary = df_dictionary.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>centrality</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>network</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>additionally</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>imply</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>tuples</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>lines</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>umann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  occurance\n",
       "index                         \n",
       "0        centrality        332\n",
       "1           network        216\n",
       "2             graph         88\n",
       "3              node         88\n",
       "4              case         56\n",
       "...             ...        ...\n",
       "449    additionally          2\n",
       "450           imply          2\n",
       "451          tuples          2\n",
       "452           lines          2\n",
       "453           umann          2\n",
       "\n",
       "[454 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export\n",
    "df_dictionary_filtered.to_json(file_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
