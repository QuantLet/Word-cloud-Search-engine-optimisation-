{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "time elapsed:  1.232071000000019\n",
      "2\n",
      "time elapsed:  0.7685060000000021\n",
      "3\n",
      "time elapsed:  0.6274940000000129\n",
      "4\n",
      "time elapsed:  0.7648049999999671\n",
      "5\n",
      "403\n",
      "problematic file:  86 https://quantinar.s3.eu-west-3.amazonaws.com/courselet_components%2F86%2F163154601720191030+Che+Hae+DEDA+Digital+Economy+Data+Analytics_Unit_5.pdf\n",
      "time elapsed:  0.010235999999963497\n",
      "6\n",
      "time elapsed:  1.6750789999999824\n",
      "7\n",
      "time elapsed:  0.9135440000000017\n",
      "8\n",
      "time elapsed:  0.537524000000019\n",
      "9\n",
      "time elapsed:  1.8698689999999942\n",
      "10\n",
      "time elapsed:  0.6389580000000024\n",
      "11\n",
      "time elapsed:  1.4398769999999672\n",
      "12\n",
      "time elapsed:  1.0208030000000008\n",
      "13\n",
      "time elapsed:  1.1083380000000034\n",
      "14\n",
      "time elapsed:  0.6478610000000344\n",
      "15\n",
      "time elapsed:  0.26173400000004676\n",
      "16\n",
      "time elapsed:  0.5609540000000379\n",
      "17\n",
      "time elapsed:  1.4856240000000298\n",
      "18\n",
      "time elapsed:  1.255108000000007\n",
      "19\n",
      "time elapsed:  0.43510499999996455\n",
      "20\n",
      "time elapsed:  0.32432499999998754\n",
      "21\n",
      "time elapsed:  3.941927000000021\n",
      "22\n",
      "time elapsed:  0.27085599999998067\n",
      "23\n",
      "time elapsed:  0.7071219999999698\n",
      "24\n",
      "time elapsed:  0.16126599999995506\n",
      "25\n",
      "time elapsed:  1.9465910000000122\n",
      "26\n",
      "time elapsed:  0.7274519999999711\n",
      "27\n",
      "time elapsed:  0.8771079999999642\n",
      "28\n",
      "time elapsed:  0.3372850000000085\n",
      "29\n",
      "time elapsed:  1.147662999999966\n",
      "30\n",
      "time elapsed:  0.4330290000000332\n",
      "31\n",
      "time elapsed:  0.31936600000000226\n",
      "32\n",
      "time elapsed:  0.4827099999999973\n",
      "33\n",
      "time elapsed:  0.6790309999999522\n",
      "34\n",
      "time elapsed:  0.33925899999997\n",
      "35\n",
      "time elapsed:  0.4736679999999751\n",
      "36\n",
      "time elapsed:  1.3337750000000028\n",
      "37\n",
      "time elapsed:  0.5161240000000475\n",
      "38\n",
      "time elapsed:  1.1565390000000093\n",
      "39\n",
      "time elapsed:  0.14998800000000756\n",
      "40\n",
      "time elapsed:  0.05631599999998116\n",
      "41\n",
      "time elapsed:  0.6472299999999791\n",
      "42\n",
      "time elapsed:  0.12699299999997038\n",
      "43\n",
      "time elapsed:  0.3916629999999941\n",
      "44\n",
      "time elapsed:  0.17062800000002198\n",
      "45\n",
      "time elapsed:  0.24178399999999556\n",
      "46\n",
      "time elapsed:  0.3069340000000125\n",
      "47\n",
      "time elapsed:  0.13941699999998036\n",
      "48\n",
      "time elapsed:  0.47039499999999634\n",
      "49\n",
      "time elapsed:  0.9096590000000333\n",
      "50\n",
      "time elapsed:  0.20626800000002277\n",
      "51\n",
      "time elapsed:  0.3816799999999603\n",
      "52\n",
      "time elapsed:  0.30884200000002693\n",
      "53\n",
      "403\n",
      "problematic file:  157 https://quantinar.s3.eu-west-3.amazonaws.com/courselet_components%2F157%2F1642778303introduction_data_science.pdf\n",
      "time elapsed:  0.009836000000007061\n",
      "54\n",
      "time elapsed:  0.3623640000000137\n",
      "55\n",
      "time elapsed:  0.5791710000000307\n",
      "56\n",
      "time elapsed:  0.694972000000007\n",
      "57\n",
      "time elapsed:  0.3050230000000056\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:  2.397307000000012\n",
      "59\n",
      "time elapsed:  0.24651399999999057\n",
      "60\n",
      "time elapsed:  0.08932699999996885\n",
      "61\n",
      "time elapsed:  0.21971600000000535\n",
      "62\n",
      "time elapsed:  0.24805299999997033\n",
      "63\n",
      "time elapsed:  0.8906010000000038\n",
      "64\n",
      "time elapsed:  0.18825499999996964\n",
      "65\n",
      "time elapsed:  0.43876699999998436\n",
      "66\n",
      "time elapsed:  0.7533210000000281\n",
      "67\n",
      "time elapsed:  0.1439799999999991\n",
      "68\n",
      "time elapsed:  0.22842800000000807\n",
      "69\n",
      "time elapsed:  0.5612700000000359\n",
      "70\n",
      "time elapsed:  0.47011399999996684\n",
      "71\n",
      "time elapsed:  0.5046800000000076\n",
      "72\n",
      "time elapsed:  0.5486430000000269\n",
      "73\n",
      "problematic file:  200 https://quantinar.s3.eu-west-3.amazonaws.com/courselet_components%2F200%2F1642686124163527012720210526+SAE+NAG+HAE+SIZ+Understanding+jumps+in+high+frequency+digital+asset+markets_course.pdf\n",
      "time elapsed:  0.10823199999998678\n",
      "74\n",
      "time elapsed:  0.3263059999999882\n",
      "75\n",
      "time elapsed:  1.1612759999999867\n",
      "76\n",
      "time elapsed:  0.9899650000000406\n",
      "77\n",
      "time elapsed:  1.1232410000000073\n",
      "78\n",
      "time elapsed:  1.1146270000000413\n",
      "79\n",
      "time elapsed:  1.1595250000000306\n",
      "80\n",
      "time elapsed:  1.1490689999999972\n",
      "81\n",
      "time elapsed:  0.6645780000000059\n",
      "82\n",
      "time elapsed:  0.8929479999999899\n",
      "83\n",
      "time elapsed:  1.970719000000031\n",
      "84\n",
      "time elapsed:  0.9712549999999851\n",
      "85\n",
      "time elapsed:  1.3036139999999818\n",
      "86\n",
      "time elapsed:  1.7892239999999902\n",
      "87\n",
      "time elapsed:  1.7180440000000203\n",
      "88\n",
      "time elapsed:  4.91947799999997\n",
      "89\n",
      "time elapsed:  3.6663450000000353\n",
      "90\n",
      "time elapsed:  3.6462680000000205\n",
      "91\n",
      "time elapsed:  3.80564099999998\n",
      "92\n",
      "time elapsed:  0.38003399999996645\n",
      "93\n",
      "time elapsed:  2.2240940000000364\n",
      "94\n",
      "time elapsed:  5.774772000000041\n",
      "95\n",
      "time elapsed:  5.743687000000023\n",
      "96\n",
      "time elapsed:  5.680406000000005\n",
      "97\n",
      "time elapsed:  1.4953409999999963\n",
      "98\n",
      "time elapsed:  0.33531399999998257\n",
      "99\n",
      "time elapsed:  1.6073999999999842\n",
      "100\n",
      "time elapsed:  1.464127000000019\n",
      "101\n",
      "time elapsed:  0.2832899999999654\n",
      "102\n",
      "time elapsed:  1.7406260000000202\n",
      "103\n",
      "time elapsed:  2.558332000000007\n",
      "104\n",
      "time elapsed:  1.438477999999975\n",
      "105\n",
      "time elapsed:  2.5802529999999706\n",
      "106\n",
      "time elapsed:  0.5893179999999916\n",
      "107\n",
      "time elapsed:  0.37736900000004425\n",
      "108\n",
      "time elapsed:  1.6213579999999865\n",
      "109\n",
      "time elapsed:  1.4135129999999663\n",
      "110\n",
      "time elapsed:  0.33505700000000616\n",
      "111\n",
      "time elapsed:  0.1832069999999817\n",
      "112\n",
      "time elapsed:  0.1109819999999786\n",
      "113\n",
      "time elapsed:  0.05598599999996168\n",
      "114\n",
      "time elapsed:  0.1372570000000337\n",
      "115\n",
      "time elapsed:  0.05456200000003264\n",
      "116\n",
      "time elapsed:  0.19274500000000216\n",
      "117\n",
      "time elapsed:  0.32089500000000726\n",
      "118\n",
      "time elapsed:  0.10148800000001756\n",
      "119\n",
      "time elapsed:  0.25377199999996947\n",
      "120\n",
      "time elapsed:  0.23648600000001352\n",
      "121\n",
      "time elapsed:  0.1505019999999604\n",
      "122\n",
      "time elapsed:  0.12004500000000462\n",
      "123\n",
      "time elapsed:  3.033555999999976\n",
      "124\n",
      "time elapsed:  2.47190599999999\n",
      "125\n",
      "time elapsed:  0.17377500000003465\n",
      "126\n",
      "time elapsed:  1.4326900000000364\n",
      "127\n",
      "time elapsed:  0.1828750000000241\n",
      "128\n",
      "time elapsed:  0.09478999999998905\n",
      "129\n",
      "time elapsed:  0.3814519999999675\n",
      "130\n",
      "time elapsed:  0.22567800000001625\n",
      "131\n",
      "time elapsed:  0.5024109999999951\n",
      "132\n",
      "time elapsed:  0.13792699999999058\n",
      "133\n",
      "403\n",
      "problematic file:  298 https://quantinar.s3.eu-west-3.amazonaws.com/courselet_components%2F298%2F20220728+Lia+Che+Che+Robo-advising+under+rare+disasters.pdf\n",
      "time elapsed:  0.009922000000017306\n",
      "134\n",
      "time elapsed:  24.80429399999997\n",
      "135\n",
      "time elapsed:  0.74383499999999\n",
      "136\n",
      "time elapsed:  1.0263340000000198\n",
      "137\n",
      "time elapsed:  0.3704559999999901\n",
      "138\n",
      "time elapsed:  0.6622010000000387\n",
      "139\n",
      "time elapsed:  1.3734130000000278\n",
      "140\n",
      "time elapsed:  1.359628999999984\n",
      "141\n",
      "time elapsed:  0.9093740000000139\n",
      "142\n",
      "time elapsed:  0.7205020000000104\n",
      "143\n",
      "time elapsed:  0.8219869999999787\n",
      "144\n",
      "time elapsed:  0.7852699999999686\n",
      "145\n",
      "time elapsed:  1.4450269999999819\n",
      "146\n",
      "time elapsed:  2.887411000000043\n",
      "147\n",
      "time elapsed:  0.7901800000000208\n",
      "148\n",
      "time elapsed:  0.19957099999993488\n",
      "149\n",
      "time elapsed:  0.6130550000000312\n",
      "150\n",
      "time elapsed:  0.134412999999995\n",
      "151\n",
      "time elapsed:  0.18724100000008548\n",
      "152\n",
      "time elapsed:  0.3133060000000114\n",
      "153\n",
      "time elapsed:  0.34542399999997997\n",
      "154\n",
      "time elapsed:  1.0102429999999458\n",
      "155\n",
      "time elapsed:  1.4826789999999619\n",
      "156\n",
      "time elapsed:  0.3560250000000451\n",
      "157\n",
      "time elapsed:  1.1248339999999644\n",
      "158\n",
      "time elapsed:  0.14781199999993078\n",
      "problematic file encountered\n",
      "search term:  ['price', 'hedg', 'invers', 'btc', 'option']\n",
      "search result: present\n",
      "\n",
      "{\"0\":{\"id\":282},\"1\":{\"id\":79},\"2\":{\"id\":266},\"3\":{\"id\":239},\"4\":{\"id\":240}}\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2, re, time, requests, os\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "# search terms\n",
    "input_initial = 'Pricing and hedging inverse BTC options'\n",
    "number_of_urls = 5\n",
    "\n",
    "# fetching all pdfs\n",
    "url_text = 'https://raw.githubusercontent.com/IvanKotik/Word-cloud-Search-engine-optimisation-/419447491efef2bb3a21b0459e5bdcd352a39097/combined_pdf_json.json'\n",
    "r = requests.get(url_text)\n",
    "combined_pdf = r.json()\n",
    "\n",
    "\n",
    "# fetching master list\n",
    "url_master = 'https://raw.githubusercontent.com/IvanKotik/Word-cloud-Search-engine-optimisation-/master/q-master-json.json'\n",
    "e = requests.get(url_master)\n",
    "q_master_json = e.json()\n",
    "\n",
    "\n",
    "# dataframing master list\n",
    "q_master = pd.DataFrame({'id' : [q_master_json[str(i)]['id'] for i in range(len(q_master_json))],\n",
    "'name' : [q_master_json[str(i)]['name'] for i in range(len(q_master_json))],\n",
    "'team' : [q_master_json[str(i)]['team'] for i in range(len(q_master_json))],\n",
    "'artist' : [q_master_json[str(i)]['artist'] for i in range(len(q_master_json))],\n",
    "'author' : [q_master_json[str(i)]['author'] for i in range(len(q_master_json))],\n",
    "'published_in' : [q_master_json[str(i)]['published_in'] for i in range(len(q_master_json))],\n",
    "'full_link' : [q_master_json[str(i)]['full_link'] for i in range(len(q_master_json))],\n",
    "'pdf_url' : [q_master_json[str(i)]['pdf_url'] for i in range(len(q_master_json))]\n",
    "})\n",
    "q_master['url_check'] = [len(i) for i in q_master['pdf_url']]\n",
    "q_master = q_master.loc[q_master['url_check'] != 0, ]\n",
    "q_master = q_master.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# fetching fresh master\n",
    "url_fresh_master = 'https://quantinar.com/api/flower/index'\n",
    "t = requests.get(url_fresh_master)\n",
    "q_fresh_json = t.json()\n",
    "\n",
    "\n",
    "# fresh master dataframing\n",
    "q_check = pd.DataFrame({'id' : [q_fresh_json['data'][i]['id'] for i in range(len(q_fresh_json['data']))],\n",
    "'name' : [q_fresh_json['data'][i]['name'] for i in range(len(q_fresh_json['data']))],\n",
    "'team' : [q_fresh_json['data'][i]['team'] for i in range(len(q_fresh_json['data']))],\n",
    "'artist' : [q_fresh_json['data'][i]['artist'] for i in range(len(q_fresh_json['data']))],\n",
    "'author' : [q_fresh_json['data'][i]['author'] for i in range(len(q_fresh_json['data']))],\n",
    "'published_in' : [q_fresh_json['data'][i]['published_in'] for i in range(len(q_fresh_json['data']))],\n",
    "'full_link' : [q_fresh_json['data'][i]['full_link'] for i in range(len(q_fresh_json['data']))],\n",
    "'pdf_url' : [q_fresh_json['data'][i]['pdf_url'] for i in range(len(q_fresh_json['data']))]\n",
    "})\n",
    "q_check['url_check'] = [len(i) for i in q_check['pdf_url']]\n",
    "q_check = q_check.loc[q_check['url_check'] != 0, ]\n",
    "q_check = q_check.reset_index(drop=True)\n",
    "\n",
    "\n",
    "stopwords_list = {\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"you're\",\"you've\",\"you'll\",\"you'd\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"she's\",\"her\",\"hers\",\"herself\",\"it\",\"it's\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",'that',\"that'll\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"don't\",\"should\",\"should've\",\"now\",\"d\",\"ll\",\"m\",\"o\",\"re\",\"ve\",\"y\",\"ain\",\"aren\",\"aren't\",\"couldn\",\"couldn't\",\"didn\",\"didn't\",\"doesn\",\"doesn't\",\"hadn\",\"hadn't\",\"hasn\",\"hasn't\",\"haven\",\"haven't\",\"isn\",\"isn't\",\"ma\",\"mightn\",\"mightn't\",\"mustn\",\"mustn't\",\"needn\",\"needn't\",\"shan\",\"shan't\",\"shouldn\",\"shouldn't\",\"wasn\",\"wasn't\",\"weren\",\"weren't\",\"won\",\"won't\",\"wouldn\",\"wouldn't\"}\n",
    "\n",
    "\n",
    "def download_pdf(file_name, url):\n",
    "\n",
    "    '''Download a PDF file with an URL'''\n",
    "\n",
    "    # Define HTTP Headers\n",
    "    headers = {\"User-Agent\": \"Chrome/51.0.2704.103\"}\n",
    "    \n",
    "    # Download image\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # response = requests.get(url)\n",
    "    \n",
    "    # if response is OK download the PDF and store it, else write the status\n",
    "    if response.status_code == 200:\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def create_string(file_name, url):\n",
    "    \n",
    "    download_pdf(file_name, url)\n",
    "\n",
    "    '''Transform a PDF file to a list of string pages'''\n",
    "    \n",
    "    # opening the file\n",
    "    imported_pdf = open(file_name, 'rb')\n",
    "    os.remove(file_name)\n",
    "    \n",
    "    # convert PDF to readable file\n",
    "    transformed_pdf = PyPDF2.PdfFileReader(imported_pdf, strict=False)\n",
    "    \n",
    "    # get number of pages\n",
    "    totalpages = transformed_pdf.numPages\n",
    "    \n",
    "    # read the data and store in a list\n",
    "    pdf_output = [transformed_pdf.getPage(i) for i in range(totalpages)]\n",
    "\n",
    "    # extract result\n",
    "    pdf_output = [pdf_output[i].extractText() for i in range(totalpages)]\n",
    "    \n",
    "    return pdf_output, totalpages \n",
    "\n",
    "\n",
    "def cleaning(file_name, url):\n",
    "\n",
    "    '''Initial PDF cleaning procedure'''\n",
    "    \n",
    "    pdf_output, totalpages = create_string(file_name, url)\n",
    "    \n",
    "    # # cleaning URLs\n",
    "    pdf_output = [re.sub(pattern = \"http[^ ]*\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning symbols\n",
    "    pdf_output = [re.sub(pattern = \"\\\\n\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"\\W|\\d\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"[^a-zA-Z]\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning multispaces\n",
    "    pdf_output = [re.sub(pattern = \"\\s{2,}\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning out 1-2-worders\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # lower-casing\n",
    "    pdf_output = [pdf_output[i].lower() for i in range(totalpages)]\n",
    "    pdf_output = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in pdf_output]\n",
    "    pdf_output = [' '.join(pdf_output[i]) for i in range(len(pdf_output))]\n",
    "    \n",
    "    return pdf_output, totalpages\n",
    "\n",
    "\n",
    "def combined_pdf_creator():\n",
    "    '''Creating the final master-pdf dataframe'''\n",
    "\n",
    "    # clean the first pdf\n",
    "    pdf_output, totalpages = cleaning(str(q_master.iloc[0, 0]), q_master.iloc[0 ,7])\n",
    "\n",
    "    # combine the pdf\n",
    "    combined_pdf = [' '.join(pdf_output)]\n",
    "\n",
    "    # iterate on above\n",
    "    for i in range(1, q_master.shape[0]):\n",
    "        print(i)\n",
    "        t = time.process_time()\n",
    "        try:\n",
    "            pdf_output, totalpages = cleaning(str(q_master.iloc[i, 0]), q_master.iloc[i ,7])\n",
    "            combined_pdf.append(' '.join(pdf_output))\n",
    "        except:\n",
    "            print('problematic file: ', str(q_master.iloc[i, 0]), q_master.iloc[i ,7])\n",
    "            combined_pdf.append(' '.join(''))\n",
    "        finally:\n",
    "            print('time elapsed: ', (time.process_time() - t))\n",
    "    return combined_pdf\n",
    "\n",
    "\n",
    "# if triggered, then it means that the pdf downloading must happen again\n",
    "if all([any(o == q_master['id']) for o in [i for i in q_check['id']]]) == False:\n",
    "    combined_pdf = combined_pdf_creator()\n",
    "    try:\n",
    "        combined_pdf_df = pd.DataFrame({'id' : q_check['id'], \"text\" : combined_pdf})\n",
    "        combined_pdf_json = combined_pdf_df.to_json(orient='index')\n",
    "        with open(\"combined_pdf_json.json\", \"w\") as outfile:\n",
    "            outfile.write(combined_pdf_json)\n",
    "    except: print('problematic file encountered')\n",
    "else: \n",
    "    combined_pdf = [combined_pdf[str(i)]['text'] for i in range(len(combined_pdf))]\n",
    "\n",
    "\n",
    "def input_sequence(input_initial): \n",
    "\n",
    "    '''Trimming input search terms to be used for the occurrence matrix. The output is a generalized stemmed input form ready for checking and a count of terms for the ngram_range.'''\n",
    "\n",
    "    # splitting the phrase by pieces\n",
    "    input_general = input_initial.split(' ')\n",
    "\n",
    "    # cleaning stopwords\n",
    "    input_general = [i for i in input_general if i not in stopwords_list]\n",
    "\n",
    "    # count words\n",
    "    input_general_count = len(input_general)\n",
    "\n",
    "    # stem the words\n",
    "    input_general = [ps.stem(i) for i in input_general]\n",
    "\n",
    "    # create the additional variations of the phrase\n",
    "    outer_list = []\n",
    "    for i in range(0, input_general_count):\n",
    "        inner_list = [input_general[j : input_general_count-i+j] for j in range(i+1)]\n",
    "        outer_list.append(inner_list)\n",
    "\n",
    "    return input_general, input_general_count, outer_list\n",
    "\n",
    "\n",
    "def general_occurrence(input_general_count, combined_pdf): \n",
    "\n",
    "    '''Creation of the generalized tfidf occurance matrix based on dynamic parameters.'''\n",
    "\n",
    "    vectorizer_general = TfidfVectorizer(smooth_idf=True, sublinear_tf=True, use_idf=True, lowercase=False, stop_words=stopwords_list, ngram_range=(input_general_count, input_general_count))\n",
    "    X_general = vectorizer_general.fit_transform(combined_pdf)\n",
    "    xx_general = pd.DataFrame(X_general.toarray(), columns = vectorizer_general.get_feature_names_out())\n",
    "    return xx_general\n",
    "\n",
    "def check_for_general(input_initial, input_general_count, outer_list, combined_pdf, number_of_urls):\n",
    "\n",
    "    '''Main function.'''\n",
    "\n",
    "    # initiating a breaker function\n",
    "    breaker = 0\n",
    "    # creating the occurrence matrix for max length\n",
    "    xx_general = general_occurrence(input_general_count, combined_pdf)\n",
    "    # creating an empty table for results\n",
    "    test_output = xx_general.copy()\n",
    "    test_output = test_output.iloc[:,0]*0\n",
    "    # first test for full match\n",
    "    print('search term: ', outer_list[0][0])\n",
    "    test = ' '.join(outer_list[0][0])\n",
    "    # if test passed\n",
    "    if test in list(xx_general.columns):\n",
    "        # create a ranked index\n",
    "        ranked_indexes = xx_general[test].sort_values(ascending=False).index\n",
    "        ranked_indexes = list(ranked_indexes[0:number_of_urls])\n",
    "        # connect back to urls\n",
    "        output_url = [q_master['id'][i] for i in ranked_indexes]\n",
    "        print('search result: present\\n')\n",
    "        return output_url\n",
    "    # if test failed drill-down\n",
    "    else: \n",
    "        print('search result: not present, drill-down\\n')\n",
    "        for y in range(1, len(outer_list)):\n",
    "            # create a new occurance matrix with new ngrams\n",
    "            xx_general = general_occurrence(input_general_count-y, combined_pdf)\n",
    "            for u in range(y+1):\n",
    "                # drill-down phrase test\n",
    "                print('search term: ', outer_list[y][u])\n",
    "                test = ' '.join(outer_list[y][u])\n",
    "                # if test passed\n",
    "                if test in list(xx_general.columns):\n",
    "                    # sum the tfidf indexes across multiple matches\n",
    "                    test_output += xx_general[test]\n",
    "                    print('search result: present\\n')\n",
    "                    # initiate the exit from the function\n",
    "                    breaker = 1\n",
    "                else: \n",
    "                    print('search result: not present\\n')\n",
    "            if breaker == 1:\n",
    "                # order the indexes by highest tfidf\n",
    "                ranked_indexes = test_output.sort_values(ascending=False).index\n",
    "                ranked_indexes = list(ranked_indexes[0:number_of_urls])\n",
    "                # return urls\n",
    "                output_url = [q_master['id'][i] for i in ranked_indexes]\n",
    "                return output_url\n",
    "\n",
    "\n",
    "input_general, input_general_count, outer_list = input_sequence(input_initial)\n",
    "output_url = check_for_general(input_initial, input_general_count, outer_list, combined_pdf, number_of_urls)\n",
    "json_output = pd.DataFrame({'id': output_url}).to_json(orient='index')\n",
    "print(json_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
