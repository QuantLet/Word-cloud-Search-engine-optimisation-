{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and main files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re, time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://quantinar.com/api/flower/index'\n",
    "r = requests.get(url)\n",
    "json_file = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_master = pd.DataFrame({'id' : [json_file['data'][i]['id'] for i in range(len(json_file['data']))],\n",
    "'name' : [json_file['data'][i]['name'] for i in range(len(json_file['data']))],\n",
    "'team' : [json_file['data'][i]['team'] for i in range(len(json_file['data']))],\n",
    "'artist' : [json_file['data'][i]['artist'] for i in range(len(json_file['data']))],\n",
    "'author' : [json_file['data'][i]['author'] for i in range(len(json_file['data']))],\n",
    "'published_in' : [json_file['data'][i]['published_in'] for i in range(len(json_file['data']))],\n",
    "'full_link' : [json_file['data'][i]['full_link'] for i in range(len(json_file['data']))],\n",
    "'pdf_url' : [json_file['data'][i]['pdf_url'] for i in range(len(json_file['data']))]\n",
    "})\n",
    "q_master['url_check'] = [len(i) for i in q_master['pdf_url']]\n",
    "q_master = q_master.loc[q_master['url_check'] != 0, ]\n",
    "q_master = q_master.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_master_json = q_master.to_json(orient='index')\n",
    "with open(\"q-master-json.json\", \"w\") as outfile:\n",
    "    outfile.write(q_master_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = {\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"you're\",\"you've\",\"you'll\",\"you'd\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"she's\",\"her\",\"hers\",\"herself\",\"it\",\"it's\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",'that',\"that'll\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"don't\",\"should\",\"should've\",\"now\",\"d\",\"ll\",\"m\",\"o\",\"re\",\"ve\",\"y\",\"ain\",\"aren\",\"aren't\",\"couldn\",\"couldn't\",\"didn\",\"didn't\",\"doesn\",\"doesn't\",\"hadn\",\"hadn't\",\"hasn\",\"hasn't\",\"haven\",\"haven't\",\"isn\",\"isn't\",\"ma\",\"mightn\",\"mightn't\",\"mustn\",\"mustn't\",\"needn\",\"needn't\",\"shan\",\"shan't\",\"shouldn\",\"shouldn't\",\"wasn\",\"wasn't\",\"weren\",\"weren't\",\"won\",\"won't\",\"wouldn\",\"wouldn't\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word bank Function definition\n",
    "## Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(file_name, url):\n",
    "\n",
    "    '''Download a PDF file with an URL'''\n",
    "\n",
    "    # Define HTTP Headers\n",
    "    headers = {\"User-Agent\": \"Chrome/51.0.2704.103\"}\n",
    "    \n",
    "    # Download image\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # response = requests.get(url)\n",
    "    \n",
    "    # if response is OK download the PDF and store it, else write the status\n",
    "    if response.status_code == 200:\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_string(file_name, url):\n",
    "    \n",
    "    download_pdf(file_name, url)\n",
    "\n",
    "    '''Transform a PDF file to a list of string pages'''\n",
    "    \n",
    "    # opening the file\n",
    "    imported_pdf = open(file_name, 'rb')\n",
    "    \n",
    "    # convert PDF to readable file\n",
    "    transformed_pdf = PyPDF2.PdfFileReader(imported_pdf, strict=False)\n",
    "    \n",
    "    # get number of pages\n",
    "    totalpages = transformed_pdf.numPages\n",
    "    \n",
    "    # read the data and store in a list\n",
    "    pdf_output = [transformed_pdf.getPage(i) for i in range(totalpages)]\n",
    "\n",
    "    # extract result\n",
    "    pdf_output = [pdf_output[i].extractText() for i in range(totalpages)]\n",
    "    \n",
    "    return pdf_output, totalpages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(file_name, url):\n",
    "\n",
    "    '''Initial PDF cleaning procedure'''\n",
    "    \n",
    "    pdf_output, totalpages = create_string(file_name, url)\n",
    "    \n",
    "    # # cleaning URLs\n",
    "    pdf_output = [re.sub(pattern = \"http[^ ]*\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning symbols\n",
    "    pdf_output = [re.sub(pattern = \"\\\\n\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"\\W|\\d\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \"[^a-zA-Z]\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning multispaces\n",
    "    pdf_output = [re.sub(pattern = \"\\s{2,}\", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # cleaning out 1-2-worders\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    pdf_output = [re.sub(pattern = \" .{1,2} \", repl = \" \", string = pdf_output[i]) for i in range(totalpages)]\n",
    "    \n",
    "    # # lower-casing\n",
    "    pdf_output = [pdf_output[i].lower() for i in range(totalpages)]\n",
    "    pdf_output = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in pdf_output]\n",
    "    pdf_output = [' '.join(pdf_output[i]) for i in range(len(pdf_output))]\n",
    "    \n",
    "    return pdf_output, totalpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final combined PDF creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_pdf_creator():\n",
    "    '''Creating the final master-pdf dataframe'''\n",
    "\n",
    "    # clean the first pdf\n",
    "    pdf_output, totalpages = cleaning(str(q_master.iloc[0, 0]), q_master.iloc[0 ,7])\n",
    "\n",
    "    # combine the pdf\n",
    "    combined_pdf = [' '.join(pdf_output)]\n",
    "\n",
    "    # iterate on above\n",
    "    for i in range(1, q_master.shape[0]):\n",
    "        print(i)\n",
    "        t = time.process_time()\n",
    "        try:\n",
    "            pdf_output, totalpages = cleaning(str(q_master.iloc[i, 0]), q_master.iloc[i ,7])\n",
    "            combined_pdf.append(' '.join(pdf_output))\n",
    "        except:\n",
    "            print('problematic file: ', str(q_master.iloc[i, 0]), q_master.iloc[i ,7])\n",
    "            combined_pdf.append(' '.join(''))\n",
    "        finally:\n",
    "            print('time elapsed: ', (time.process_time() - t))\n",
    "    return combined_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and search function definitions\n",
    "## Search input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sequence(input_initial): \n",
    "\n",
    "    '''Trimming input search terms to be used for the occurrence matrix. The output is a generalized stemmed input form ready for checking and a count of terms for the ngram_range.'''\n",
    "\n",
    "    # splitting the phrase by pieces\n",
    "    input_general = input_initial.split(' ')\n",
    "\n",
    "    # cleaning stopwords\n",
    "    input_general = [i for i in input_general if i not in stopwords_list]\n",
    "\n",
    "    # count words\n",
    "    input_general_count = len(input_general)\n",
    "\n",
    "    # stem the words\n",
    "    input_general = [ps.stem(i) for i in input_general]\n",
    "\n",
    "    # create the additional variations of the phrase\n",
    "    outer_list = []\n",
    "    for i in range(0, input_general_count):\n",
    "        inner_list = [input_general[j : input_general_count-i+j] for j in range(i+1)]\n",
    "        outer_list.append(inner_list)\n",
    "\n",
    "    return input_general, input_general_count, outer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_occurrence(input_general_count, combined_pdf): \n",
    "\n",
    "    '''Creation of the generalized tfidf occurance matrix based on dynamic parameters.'''\n",
    "\n",
    "    vectorizer_general = TfidfVectorizer(smooth_idf=True, sublinear_tf=True, use_idf=True, lowercase=False, stop_words=stopwords_list, ngram_range=(input_general_count, input_general_count))\n",
    "    X_general = vectorizer_general.fit_transform(combined_pdf)\n",
    "    xx_general = pd.DataFrame(X_general.toarray(), columns = vectorizer_general.get_feature_names_out())\n",
    "    return xx_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_general(input_initial, input_general_count, outer_list, combined_pdf, number_of_urls):\n",
    "\n",
    "    '''Main function.'''\n",
    "\n",
    "    # initiating a breaker function\n",
    "    breaker = 0\n",
    "    # creating the occurrence matrix for max length\n",
    "    xx_general = general_occurrence(input_general_count, combined_pdf)\n",
    "    # creating an empty table for results\n",
    "    test_output = xx_general.copy()\n",
    "    test_output = test_output.iloc[:,0]*0\n",
    "    # first test for full match\n",
    "    print('search term: ', outer_list[0][0])\n",
    "    test = ' '.join(outer_list[0][0])\n",
    "    # if test passed\n",
    "    if test in list(xx_general.columns):\n",
    "        # create a ranked index\n",
    "        ranked_indexes = xx_general[test].sort_values(ascending=False).index\n",
    "        ranked_indexes = list(ranked_indexes[0:number_of_urls])\n",
    "        # connect back to urls\n",
    "        output_url = [q_master['id'][i] for i in ranked_indexes]\n",
    "        print('search result: present\\n')\n",
    "        return output_url\n",
    "    # if test failed drill-down\n",
    "    else: \n",
    "        print('search result: not present, drill-down\\n')\n",
    "        for y in range(1, len(outer_list)):\n",
    "            # create a new occurance matrix with new ngrams\n",
    "            xx_general = general_occurrence(input_general_count-y, combined_pdf)\n",
    "            for u in range(y+1):\n",
    "                # drill-down phrase test\n",
    "                print('search term: ', outer_list[y][u])\n",
    "                test = ' '.join(outer_list[y][u])\n",
    "                # if test passed\n",
    "                if test in list(xx_general.columns):\n",
    "                    # sum the tfidf indexes across multiple matches\n",
    "                    test_output += xx_general[test]\n",
    "                    print('search result: present\\n')\n",
    "                    # initiate the exit from the function\n",
    "                    breaker = 1\n",
    "                else: \n",
    "                    print('search result: not present\\n')\n",
    "            if breaker == 1:\n",
    "                # order the indexes by highest tfidf\n",
    "                ranked_indexes = test_output.sort_values(ascending=False).index\n",
    "                ranked_indexes = list(ranked_indexes[0:number_of_urls])\n",
    "                # return urls\n",
    "                output_url = [q_master['id'][i] for i in ranked_indexes]\n",
    "                return output_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "time elapsed:  1.2463730000000055\n",
      "2\n",
      "time elapsed:  0.8488540000000171\n",
      "3\n",
      "time elapsed:  0.6128999999999678\n",
      "4\n",
      "time elapsed:  0.8392120000000318\n",
      "5\n",
      "time elapsed:  0.8427849999999921\n",
      "6\n",
      "time elapsed:  1.8208640000000287\n",
      "7\n",
      "time elapsed:  1.0670389999999657\n",
      "8\n",
      "time elapsed:  0.5367709999999875\n",
      "9\n",
      "time elapsed:  1.9320859999999698\n",
      "10\n",
      "time elapsed:  0.7196099999999888\n",
      "11\n",
      "time elapsed:  1.4151750000000334\n",
      "12\n",
      "time elapsed:  1.0184229999999843\n",
      "13\n",
      "time elapsed:  1.2061990000000264\n",
      "14\n",
      "time elapsed:  0.6304279999999949\n",
      "15\n",
      "time elapsed:  0.2721569999999929\n",
      "16\n",
      "time elapsed:  0.7624889999999596\n",
      "17\n",
      "time elapsed:  1.6125630000000228\n",
      "18\n",
      "time elapsed:  1.5120539999999778\n",
      "19\n",
      "time elapsed:  0.5663619999999696\n",
      "20\n",
      "time elapsed:  0.39819800000003625\n",
      "21\n",
      "time elapsed:  4.035685000000001\n",
      "22\n",
      "time elapsed:  0.29297699999995075\n",
      "23\n",
      "time elapsed:  0.8151900000000296\n",
      "24\n",
      "time elapsed:  0.1747519999999554\n",
      "25\n",
      "time elapsed:  2.022788999999989\n",
      "26\n",
      "time elapsed:  0.8552540000000022\n",
      "27\n",
      "time elapsed:  1.1886740000000486\n",
      "28\n",
      "time elapsed:  0.36199000000004844\n",
      "29\n",
      "time elapsed:  1.2216439999999693\n",
      "30\n",
      "time elapsed:  0.681474000000037\n",
      "31\n",
      "time elapsed:  0.38621899999998277\n",
      "32\n",
      "time elapsed:  0.6472100000000296\n",
      "33\n",
      "time elapsed:  1.0372290000000248\n",
      "34\n",
      "time elapsed:  0.31245400000000245\n",
      "35\n",
      "time elapsed:  0.5853199999999674\n",
      "36\n",
      "time elapsed:  1.6237189999999941\n",
      "37\n",
      "time elapsed:  0.5871759999999995\n",
      "38\n",
      "time elapsed:  1.17118099999999\n",
      "39\n",
      "time elapsed:  0.28572900000000345\n",
      "40\n",
      "time elapsed:  0.10861300000004803\n",
      "41\n",
      "time elapsed:  0.9273790000000304\n",
      "42\n",
      "time elapsed:  0.17193599999995968\n",
      "43\n",
      "time elapsed:  0.4642799999999738\n",
      "44\n",
      "time elapsed:  0.19558399999999665\n",
      "45\n",
      "time elapsed:  0.26254000000000133\n",
      "46\n",
      "time elapsed:  0.26282400000002326\n",
      "47\n",
      "time elapsed:  0.2776920000000018\n",
      "48\n",
      "time elapsed:  0.44208800000001247\n",
      "49\n",
      "time elapsed:  1.0660429999999792\n",
      "50\n",
      "time elapsed:  0.27093600000000606\n",
      "51\n",
      "time elapsed:  0.3386199999999917\n",
      "52\n",
      "time elapsed:  0.37965900000000374\n",
      "53\n",
      "time elapsed:  0.09335400000003347\n",
      "54\n",
      "time elapsed:  0.42016100000000733\n",
      "55\n",
      "time elapsed:  0.6925209999999993\n",
      "56\n",
      "time elapsed:  0.7642119999999863\n",
      "57\n",
      "time elapsed:  0.3894790000000512\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M7\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M8\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M1\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M2\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M3\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M4\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M5\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M6\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n",
      " impossible to decode XFormObject /M0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:  2.4501670000000217\n",
      "59\n",
      "time elapsed:  0.29718199999996386\n",
      "60\n",
      "time elapsed:  0.10714100000001281\n",
      "61\n",
      "time elapsed:  0.23178899999999203\n",
      "62\n",
      "time elapsed:  0.21000100000003386\n",
      "63\n",
      "time elapsed:  1.1136960000000045\n",
      "64\n",
      "time elapsed:  0.3212270000000217\n",
      "65\n",
      "time elapsed:  0.9605060000000094\n",
      "66\n",
      "time elapsed:  1.9931909999999675\n",
      "67\n",
      "time elapsed:  0.2822159999999485\n",
      "68\n",
      "time elapsed:  0.17592500000000655\n",
      "69\n",
      "time elapsed:  0.5277090000000157\n",
      "70\n",
      "time elapsed:  0.6784900000000107\n",
      "71\n",
      "time elapsed:  0.5311939999999709\n",
      "72\n",
      "time elapsed:  0.6882640000000038\n",
      "73\n",
      "problematic file:  200 https://quantinar.s3.eu-west-3.amazonaws.com/courselet_components%2F200%2F1642686124163527012720210526+SAE+NAG+HAE+SIZ+Understanding+jumps+in+high+frequency+digital+asset+markets_course.pdf\n",
      "time elapsed:  0.12702099999995653\n",
      "74\n",
      "time elapsed:  0.3875189999999975\n",
      "75\n",
      "time elapsed:  1.3995590000000107\n",
      "76\n",
      "time elapsed:  0.9782329999999888\n",
      "77\n",
      "time elapsed:  1.1899389999999812\n",
      "78\n",
      "time elapsed:  1.1238720000000058\n",
      "79\n",
      "time elapsed:  1.1791010000000028\n",
      "80\n",
      "time elapsed:  1.2196199999999635\n",
      "81\n",
      "time elapsed:  0.7182300000000055\n",
      "82\n",
      "time elapsed:  0.9690539999999714\n",
      "83\n",
      "time elapsed:  2.5813890000000015\n",
      "84\n",
      "time elapsed:  0.9335740000000214\n",
      "85\n",
      "time elapsed:  1.5293639999999868\n",
      "86\n",
      "time elapsed:  2.029809\n",
      "87\n",
      "time elapsed:  2.5539739999999824\n",
      "88\n",
      "time elapsed:  5.601647000000014\n",
      "89\n",
      "time elapsed:  3.7982889999999543\n",
      "90\n",
      "time elapsed:  3.7779480000000376\n",
      "91\n",
      "time elapsed:  3.9418959999999856\n",
      "92\n",
      "time elapsed:  0.7919449999999983\n",
      "93\n",
      "time elapsed:  2.1633319999999685\n",
      "94\n",
      "time elapsed:  5.741821000000016\n",
      "95\n",
      "time elapsed:  5.802605000000028\n",
      "96\n",
      "time elapsed:  5.877435000000048\n",
      "97\n",
      "time elapsed:  1.4649820000000204\n",
      "98\n",
      "time elapsed:  0.35563300000001163\n",
      "99\n",
      "time elapsed:  1.607658000000015\n",
      "100\n",
      "time elapsed:  1.558035000000018\n",
      "101\n",
      "time elapsed:  0.26117999999996755\n",
      "102\n",
      "time elapsed:  1.8470870000000446\n",
      "103\n",
      "time elapsed:  2.7319060000000377\n",
      "104\n",
      "time elapsed:  1.52837999999997\n",
      "105\n",
      "time elapsed:  2.513594000000012\n",
      "106\n",
      "time elapsed:  0.6693400000000338\n",
      "107\n",
      "time elapsed:  0.4462090000000103\n",
      "108\n",
      "time elapsed:  1.6083409999999958\n",
      "109\n",
      "time elapsed:  1.3811580000000276\n",
      "110\n",
      "time elapsed:  0.27720100000004777\n",
      "111\n",
      "time elapsed:  0.2948090000000434\n",
      "112\n",
      "time elapsed:  0.12465500000001839\n",
      "113\n",
      "time elapsed:  0.06969099999997752\n",
      "114\n",
      "time elapsed:  0.15256600000003573\n",
      "115\n",
      "time elapsed:  0.050640999999984615\n",
      "116\n",
      "time elapsed:  0.21881100000001652\n",
      "117\n",
      "time elapsed:  0.35224999999996953\n",
      "118\n",
      "time elapsed:  0.11757000000000062\n",
      "119\n",
      "time elapsed:  0.20900600000004488\n",
      "120\n",
      "time elapsed:  0.2511840000000234\n",
      "121\n",
      "time elapsed:  0.217220999999995\n",
      "122\n",
      "time elapsed:  0.3261449999999968\n",
      "123\n",
      "time elapsed:  2.9610799999999813\n",
      "124\n",
      "time elapsed:  2.5602949999999964\n",
      "125\n",
      "time elapsed:  0.19020000000000437\n",
      "126\n",
      "time elapsed:  1.4942360000000008\n",
      "127\n",
      "time elapsed:  0.1505239999999617\n",
      "128\n",
      "time elapsed:  0.11653499999999894\n",
      "129\n",
      "time elapsed:  0.3876329999999939\n",
      "130\n",
      "time elapsed:  0.1660630000000083\n",
      "131\n",
      "time elapsed:  0.5753780000000006\n",
      "132\n",
      "time elapsed:  0.17383000000000948\n",
      "133\n",
      "time elapsed:  0.20560499999999138\n",
      "134\n",
      "time elapsed:  25.364153999999985\n",
      "135\n",
      "time elapsed:  0.8651550000000157\n",
      "136\n",
      "time elapsed:  0.7462519999999699\n",
      "137\n",
      "time elapsed:  0.3930990000000065\n",
      "138\n",
      "time elapsed:  0.5443290000000047\n",
      "139\n",
      "time elapsed:  1.1192649999999844\n",
      "140\n",
      "time elapsed:  1.4605410000000347\n",
      "141\n",
      "time elapsed:  0.9691799999999944\n",
      "142\n",
      "time elapsed:  0.6549350000000231\n",
      "143\n",
      "time elapsed:  0.8653400000000033\n",
      "144\n",
      "time elapsed:  0.7340479999999729\n",
      "145\n",
      "time elapsed:  1.4650330000000054\n",
      "146\n",
      "time elapsed:  2.8234539999999697\n",
      "147\n",
      "time elapsed:  0.9394869999999855\n",
      "148\n",
      "time elapsed:  0.23726400000003878\n",
      "149\n",
      "time elapsed:  0.6345249999999965\n",
      "150\n",
      "time elapsed:  0.16833100000002332\n",
      "151\n",
      "time elapsed:  0.1750589999999761\n",
      "152\n",
      "time elapsed:  0.38242400000001453\n",
      "153\n",
      "time elapsed:  0.37471100000004753\n",
      "154\n",
      "time elapsed:  0.9692770000000337\n",
      "155\n",
      "time elapsed:  1.4833340000000135\n",
      "156\n",
      "time elapsed:  0.30289899999996805\n",
      "157\n",
      "time elapsed:  1.3170349999999758\n",
      "158\n",
      "time elapsed:  0.36667600000004086\n"
     ]
    }
   ],
   "source": [
    "combined_pdf = combined_pdf_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search term:  ['price', 'hedg', 'invers', 'btc', 'option']\n",
      "search result: present\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[282, 79, 266, 239, 240]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_initial = 'Pricing and hedging inverse BTC options'\n",
    "number_of_urls = 5\n",
    "input_general, input_general_count, outer_list = input_sequence(input_initial)\n",
    "check_for_general(input_initial, input_general_count, outer_list, combined_pdf, number_of_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Output script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search term:  ['price', 'hedg', 'invers', 'btc', 'option']\n",
      "search result: present\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_initial = 'Pricing and hedging inverse BTC options'\n",
    "number_of_urls = 5\n",
    "input_general, input_general_count, outer_list = input_sequence(input_initial)\n",
    "output_url = check_for_general(input_initial, input_general_count, outer_list, combined_pdf, number_of_urls)\n",
    "json_output = pd.DataFrame({'id': output_url}).to_json(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pdf_df = pd.DataFrame({'id' : q_master['id'], \"text\" : combined_pdf})\n",
    "combined_pdf_df\n",
    "combined_pdf_json = combined_pdf_df.to_json(orient='index')\n",
    "combined_pdf_json\n",
    "with open(\"combined_pdf_json.json\", \"w\") as outfile:\n",
    "    outfile.write(combined_pdf_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_index = 0\n",
    "url = 'https://quantinar.com/api/flower/index'\n",
    "r = requests.get(url)\n",
    "json_file = r.json()\n",
    "\n",
    "q_check = pd.DataFrame({'id' : [json_file['data'][i]['id'] for i in range(len(json_file['data']))],\n",
    "'name' : [json_file['data'][i]['name'] for i in range(len(json_file['data']))],\n",
    "'team' : [json_file['data'][i]['team'] for i in range(len(json_file['data']))],\n",
    "'artist' : [json_file['data'][i]['artist'] for i in range(len(json_file['data']))],\n",
    "'author' : [json_file['data'][i]['author'] for i in range(len(json_file['data']))],\n",
    "'published_in' : [json_file['data'][i]['published_in'] for i in range(len(json_file['data']))],\n",
    "'full_link' : [json_file['data'][i]['full_link'] for i in range(len(json_file['data']))],\n",
    "'pdf_url' : [json_file['data'][i]['pdf_url'] for i in range(len(json_file['data']))]\n",
    "})\n",
    "q_check['url_check'] = [len(i) for i in q_check['pdf_url']]\n",
    "q_check = q_check.loc[q_check['url_check'] != 0, ]\n",
    "q_check = q_check.reset_index(drop=True)\n",
    "\n",
    "# if triggered, then it means that the pdf downloading must happen again\n",
    "if all([any(o == q_master['id']) for o in [i for i in q_check['id']]]) == False:\n",
    "    reset_index == 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
